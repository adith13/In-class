{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce37b077-6565-4c30-a8c5-06d1109099f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42608712-ee24-4ae6-ae0e-9e534b7c7ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Take sometime and give me one of the presidential inauguration speech frequency distribution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "514c88d2-4365-46be-abf4-72a3bb8bb809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'Take': 1, 'sometime': 1, 'and': 1, 'give': 1, 'me': 1, 'one': 1, 'of': 1, 'the': 1, 'presidential': 1, 'inauguration': 1, ...})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = nltk.FreqDist(text1.split())\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f46797b7-401c-419e-b083-8b7a6e93003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import inaugural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65600250-74cb-40d4-ab88-394c2f0b88e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 106, '.': 89, 'and': 70, 'the': 65, 'of': 48, 'our': 47, 'will': 43, 'to': 37, 'We': 26, 'we': 24, ...})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd2 = nltk.FreqDist(inaugural.words(fileids = '2017-Trump.txt'))\n",
    "fd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "263fbb53-858e-40fa-987a-fae062e65863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConditionalFreqDist with 7 conditions>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conditional frequency distribution\n",
    "from nltk.probability import ConditionalFreqDist as CFD\n",
    "cfd = CFD((len(word),word) for word in text1.split())\n",
    "cfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c47b076-e43e-4065-a60e-064a92428803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'Take': 1, 'give': 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are looking for words which has 4 characters\n",
    "cfd[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de82891-3962-413c-b343-6bb1cf81e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e2b51-dd72-40a9-8af4-8a5d9fea5a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 languages that have no separatros for sentences of words Chinese, Japanese & Thai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83110469-18a9-4b63-91d7-e37e358c055e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jieba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# greedy technique is used for such languages ( GSA - Greedy Segmentation Algorithm )\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# starts searching for large meaningful words from the end of the sentence\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m seg_list_c \u001b[38;5;241m=\u001b[39m \u001b[43mjieba\u001b[49m\u001b[38;5;241m.\u001b[39mcut(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m自然语言处理\u001b[39m\u001b[38;5;124m\"\u001b[39m, cut_all \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m seg_list_c\n",
      "\u001b[1;31mNameError\u001b[0m: name 'jieba' is not defined"
     ]
    }
   ],
   "source": [
    "# greedy technique is used for such languages ( GSA - Greedy Segmentation Algorithm )\n",
    "# starts searching for large meaningful words from the end of the sentence\n",
    "seg_list_c = jieba.cut(\"自然语言处理\", cut_all = True)\n",
    "seg_list_c\n",
    "\n",
    "seg_list_j = jieba.cut(\"自然语言处理\", cut_all = True)\n",
    "seg_list_j\n",
    "\n",
    "seg_list_t = jieba.cut(\"自然语言处理\", cut_all = True)\n",
    "seg_list_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eadc84db-2739-4ac2-b8a8-96667580a059",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seg_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mseg_list\u001b[49m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'seg_list' is not defined"
     ]
    }
   ],
   "source": [
    "print(\", \".join(seg_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482c7ec-3826-44aa-9c8f-801fb320b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexicon\n",
    "# Samuel Johnson -> first lexicographer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
